import threading
import time
import cv2
import numpy as np
import torch
from queue import Queue
from pymongo import MongoClient
from facenet_pytorch import InceptionResnetV1
from retinaface import RetinaFace
from scipy.spatial.distance import cosine
from flask import Flask, Response

# ---------------------------
# Configs
# ---------------------------
CAMERA_SOURCES = {
    "Camera 1": "http://10.24.82.153:4747/video"
}
MONGO_URI = "mongodb+srv://pulkitshrivastavabtech2023:eNlJhr8xRuuQYJDX@facialrecognitiondatabs.l70mvub.mongodb.net/?retryWrites=true&w=majority&appName=FacialRecognitionDatabse"

frames = {name: Queue(maxsize=5) for name in CAMERA_SOURCES}
processed_frames = {name: Queue(maxsize=5) for name in CAMERA_SOURCES}
last_frame_cache = {}
alerted_ids = set()

# ---------------------------
# Mongo Connection
# ---------------------------
client = MongoClient(MONGO_URI)
db = client["FaceRecognition"]
known_faces_collection = db["KnownFaces"]

# ---------------------------
# Load Model
# ---------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
embedding_model = InceptionResnetV1(pretrained='vggface2').eval().to(device)

def cosine_similarity(embedding1, embedding2):
    return 1 - cosine(embedding1, embedding2)

def match_faces(detected_embedding):
    known_faces = list(known_faces_collection.find({}))
    best_match = None
    best_score = 0

    for known_face in known_faces:
        for angle, known_embedding in known_face["embeddings"].items():
            score = cosine_similarity(np.array(detected_embedding), np.array(known_embedding))
            if score > best_score:
                best_score = score
                best_match = {
                    "p_id": known_face["p_id"],
                    "angle": angle,
                    "score": best_score
                }

    return best_match if best_match and best_score > 0.6 else None

def get_embedding(face_img, landmarks=None, partial=False):
    try:
        if face_img is None or face_img.size == 0:
            return None

        if partial and landmarks:
            left_eye = landmarks["left_eye"]
            right_eye = landmarks["right_eye"]
            nose = landmarks["nose"]

            x_coords = [left_eye[0], right_eye[0], nose[0]]
            y_coords = [left_eye[1], right_eye[1], nose[1]]
            x1 = int(max(min(x_coords) - 20, 0))
            y1 = int(max(min(y_coords) - 20, 0))
            x2 = int(min(max(x_coords) + 20, face_img.shape[1]))
            y2 = int(min(max(y_coords) + 20, face_img.shape[0]))

            face_img = face_img[y1:y2, x1:x2]

        face_img = cv2.resize(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB), (160, 160)).astype(np.float32) / 255.0
        face_tensor = torch.from_numpy((face_img - 0.5) / 0.5).permute(2, 0, 1).unsqueeze(0).to(device)

        with torch.no_grad():
            embedding = embedding_model(face_tensor)
        return embedding.squeeze().cpu().numpy()
    except:
        return None

def detect_faces(camera_name):
    while True:
        if not frames[camera_name].empty():
            frame = frames[camera_name].get()
            height, width = frame.shape[:2]
            faces = RetinaFace.detect_faces(frame)
            results = []

            if isinstance(faces, dict) and faces:
                for _, face in faces.items():
                    x1, y1, x2, y2 = face["facial_area"]
                    x1, y1 = max(0, x1), max(0, y1)
                    x2, y2 = min(width - 1, x2), min(height - 1, y2)
                    if x2 <= x1 or y2 <= y1:
                        continue

                    cropped_face = frame[y1:y2, x1:x2]
                    if cropped_face.size == 0:
                        continue

                    embedding = get_embedding(cropped_face)
                    match = match_faces(embedding) if embedding is not None else None

                    if not match or match["score"] < 0.6:
                        embedding_partial = get_embedding(cropped_face, face["landmarks"], partial=True)
                        if embedding_partial is not None:
                            match_partial = match_faces(embedding_partial)
                            if match_partial and match_partial["score"] > (match["score"] if match else 0):
                                match = match_partial

                    results.append((x1, y1, x2, y2, match))

            for x1, y1, x2, y2, match in results:
                label = match["p_id"] if match else "Unknown"
                color = (0, 255, 0) if match else (0, 0, 255)
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                cv2.putText(frame, f"{label}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

            if processed_frames[camera_name].full():
                processed_frames[camera_name].get()
            processed_frames[camera_name].put(frame)
            last_frame_cache[camera_name] = frame

        time.sleep(0.03)

def capture_frames(camera_name, url):
    cap = cv2.VideoCapture(url)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

    if not cap.isOpened():
        print(f"[ERROR] Cannot open {camera_name}")
        return

    frame_counter = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.1)
            continue

        frame = cv2.resize(frame, (480, 360))
        frame_counter += 1

        if frame_counter % 5 == 0:
            if frames[camera_name].full():
                frames[camera_name].get()
            frames[camera_name].put(frame.copy())

        time.sleep(0.03)
    cap.release()

# ---------------------------
# Flask App
# ---------------------------
app = Flask(__name__)

def generate_stream():
    while True:
        frame = last_frame_cache.get("Camera 1", np.zeros((360, 480, 3), dtype=np.uint8))
        ret, jpeg = cv2.imencode('.jpg', frame)
        if not ret:
            continue
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + jpeg.tobytes() + b'\r\n')
        time.sleep(0.03)

@app.route('/')
def index():
    return '<h1>Real-Time Facial Recognition</h1><img src="/video_feed">'

@app.route('/video_feed/<camera_id>')
def video_feed(camera_id):
    def generate_stream(camera_id):
        while True:
            frame = last_frame_cache.get(camera_id, np.zeros((360, 480, 3), dtype=np.uint8))
            ret, jpeg = cv2.imencode('.jpg', frame)
            if not ret:
                continue
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + jpeg.tobytes() + b'\r\n')
            time.sleep(0.03)
    return Response(generate_stream(camera_id), mimetype='multipart/x-mixed-replace; boundary=frame')

# ---------------------------
# Start everything
# ---------------------------
if __name__ == '__main__':
    for cam_name, cam_url in CAMERA_SOURCES.items():
        threading.Thread(target=capture_frames, args=(cam_name, cam_url), daemon=True).start()
        threading.Thread(target=detect_faces, args=(cam_name,), daemon=True).start()

    app.run(host='0.0.0.0', port=5011, debug=False, use_reloader=False)
