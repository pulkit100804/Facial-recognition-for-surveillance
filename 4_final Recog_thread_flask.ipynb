{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e783d-b58c-4b1d-af96-e5adfa0420f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5011\n",
      " * Running on http://172.30.73.19:5011\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [10/Apr/2025 14:17:31] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Apr/2025 14:17:31] \"GET /video_feed HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Apr/2025 14:17:31] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from queue import Queue\n",
    "from pymongo import MongoClient\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from retinaface import RetinaFace\n",
    "from scipy.spatial.distance import cosine\n",
    "from flask import Flask, Response\n",
    "\n",
    "# ---------------------------\n",
    "# Configs\n",
    "# ---------------------------\n",
    "CAMERA_SOURCES = {\n",
    "    \"Camera 1\": \"http://10.24.82.153:4747/video\"\n",
    "}\n",
    "MONGO_URI = \"mongodb+srv://pulkitshrivastavabtech2023:eNlJhr8xRuuQYJDX@facialrecognitiondatabs.l70mvub.mongodb.net/?retryWrites=true&w=majority&appName=FacialRecognitionDatabse\"\n",
    "\n",
    "frames = {name: Queue(maxsize=5) for name in CAMERA_SOURCES}\n",
    "processed_frames = {name: Queue(maxsize=5) for name in CAMERA_SOURCES}\n",
    "last_frame_cache = {}\n",
    "alerted_ids = set()\n",
    "\n",
    "# ---------------------------\n",
    "# Mongo Connection\n",
    "# ---------------------------\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[\"FaceRecognition\"]\n",
    "known_faces_collection = db[\"KnownFaces\"]\n",
    "\n",
    "# ---------------------------\n",
    "# Load Model\n",
    "# ---------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "def match_faces(detected_embedding):\n",
    "    known_faces = list(known_faces_collection.find({}))\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    for known_face in known_faces:\n",
    "        for angle, known_embedding in known_face[\"embeddings\"].items():\n",
    "            score = cosine_similarity(np.array(detected_embedding), np.array(known_embedding))\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = {\n",
    "                    \"p_id\": known_face[\"p_id\"],\n",
    "                    \"angle\": angle,\n",
    "                    \"score\": best_score\n",
    "                }\n",
    "\n",
    "    return best_match if best_match and best_score > 0.6 else None\n",
    "\n",
    "def get_embedding(face_img, landmarks=None, partial=False):\n",
    "    try:\n",
    "        if face_img is None or face_img.size == 0:\n",
    "            return None\n",
    "\n",
    "        if partial and landmarks:\n",
    "            left_eye = landmarks[\"left_eye\"]\n",
    "            right_eye = landmarks[\"right_eye\"]\n",
    "            nose = landmarks[\"nose\"]\n",
    "\n",
    "            x_coords = [left_eye[0], right_eye[0], nose[0]]\n",
    "            y_coords = [left_eye[1], right_eye[1], nose[1]]\n",
    "            x1 = int(max(min(x_coords) - 20, 0))\n",
    "            y1 = int(max(min(y_coords) - 20, 0))\n",
    "            x2 = int(min(max(x_coords) + 20, face_img.shape[1]))\n",
    "            y2 = int(min(max(y_coords) + 20, face_img.shape[0]))\n",
    "\n",
    "            face_img = face_img[y1:y2, x1:x2]\n",
    "\n",
    "        face_img = cv2.resize(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB), (160, 160)).astype(np.float32) / 255.0\n",
    "        face_tensor = torch.from_numpy((face_img - 0.5) / 0.5).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = embedding_model(face_tensor)\n",
    "        return embedding.squeeze().cpu().numpy()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def detect_faces(camera_name):\n",
    "    while True:\n",
    "        if not frames[camera_name].empty():\n",
    "            frame = frames[camera_name].get()\n",
    "            height, width = frame.shape[:2]\n",
    "            faces = RetinaFace.detect_faces(frame)\n",
    "            results = []\n",
    "\n",
    "            if isinstance(faces, dict) and faces:\n",
    "                for _, face in faces.items():\n",
    "                    x1, y1, x2, y2 = face[\"facial_area\"]\n",
    "                    x1, y1 = max(0, x1), max(0, y1)\n",
    "                    x2, y2 = min(width - 1, x2), min(height - 1, y2)\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue\n",
    "\n",
    "                    cropped_face = frame[y1:y2, x1:x2]\n",
    "                    if cropped_face.size == 0:\n",
    "                        continue\n",
    "\n",
    "                    embedding = get_embedding(cropped_face)\n",
    "                    match = match_faces(embedding) if embedding is not None else None\n",
    "\n",
    "                    if not match or match[\"score\"] < 0.6:\n",
    "                        embedding_partial = get_embedding(cropped_face, face[\"landmarks\"], partial=True)\n",
    "                        if embedding_partial is not None:\n",
    "                            match_partial = match_faces(embedding_partial)\n",
    "                            if match_partial and match_partial[\"score\"] > (match[\"score\"] if match else 0):\n",
    "                                match = match_partial\n",
    "\n",
    "                    results.append((x1, y1, x2, y2, match))\n",
    "\n",
    "            for x1, y1, x2, y2, match in results:\n",
    "                label = match[\"p_id\"] if match else \"Unknown\"\n",
    "                color = (0, 255, 0) if match else (0, 0, 255)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, f\"{label}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            if processed_frames[camera_name].full():\n",
    "                processed_frames[camera_name].get()\n",
    "            processed_frames[camera_name].put(frame)\n",
    "            last_frame_cache[camera_name] = frame\n",
    "\n",
    "        time.sleep(0.03)\n",
    "\n",
    "def capture_frames(camera_name, url):\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] Cannot open {camera_name}\")\n",
    "        return\n",
    "\n",
    "    frame_counter = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        frame = cv2.resize(frame, (480, 360))\n",
    "        frame_counter += 1\n",
    "\n",
    "        if frame_counter % 5 == 0:\n",
    "            if frames[camera_name].full():\n",
    "                frames[camera_name].get()\n",
    "            frames[camera_name].put(frame.copy())\n",
    "\n",
    "        time.sleep(0.03)\n",
    "    cap.release()\n",
    "\n",
    "# ---------------------------\n",
    "# Flask App\n",
    "# ---------------------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "def generate_stream():\n",
    "    while True:\n",
    "        frame = last_frame_cache.get(\"Camera 1\", np.zeros((360, 480, 3), dtype=np.uint8))\n",
    "        ret, jpeg = cv2.imencode('.jpg', frame)\n",
    "        if not ret:\n",
    "            continue\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + jpeg.tobytes() + b'\\r\\n')\n",
    "        time.sleep(0.03)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return '<h1>Real-Time Facial Recognition</h1><img src=\"/video_feed\">'\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(generate_stream(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "# ---------------------------\n",
    "# Start everything\n",
    "# ---------------------------\n",
    "if __name__ == '__main__':\n",
    "    for cam_name, cam_url in CAMERA_SOURCES.items():\n",
    "        threading.Thread(target=capture_frames, args=(cam_name, cam_url), daemon=True).start()\n",
    "        threading.Thread(target=detect_faces, args=(cam_name,), daemon=True).start()\n",
    "\n",
    "    app.run(host='0.0.0.0', port=5011, debug=False, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5397869-fc71-4f9c-8639-8f8198df0fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
