{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ebd52-cc44-40ed-b35d-d7b270d5fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "from retinaface import RetinaFace\n",
    "print(\"RetinaFace successfully imported!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb55de9-1d12-4480-aa52-ea5246db43b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0])\n",
    "    b = tf.constant([4.0, 5.0, 6.0])\n",
    "    c = a * b\n",
    "    print(\"TensorFlow GPU Test:\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5292dd5-4e3d-4fc5-925b-9b4e6223dc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 13:59:30.723294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-08 13:59:31.250897: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-08 13:59:31.498762: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-08 13:59:33.022634: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/student/anaconda3/envs/tensorflow/lib/python3.10/site-packages/cv2/../../lib64:/home/student/anaconda3/envs/tensorflow/lib\n",
      "2025-03-08 13:59:33.022870: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/student/anaconda3/envs/tensorflow/lib/python3.10/site-packages/cv2/../../lib64:/home/student/anaconda3/envs/tensorflow/lib\n",
      "2025-03-08 13:59:33.022881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "import time\n",
    "from retinaface import RetinaFace\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a26f9f1-8375-4b97-bba4-3e3caf480af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TensorFlow is using GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[ERROR] Unable to open camera1. Check IP and connectivity.\n",
      "[ERROR] Lost connection to camera2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[http @ 0x7f86010207c0] Stream ends prematurely at 19058945, should be 18446744073709551615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Lost connection to camera1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[http @ 0x7f8608001cc0] Stream ends prematurely at 57317040, should be 18446744073709551615\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from queue import Queue\n",
    "from retinaface import RetinaFace\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"[INFO] TensorFlow is using GPU:\", tf.config.list_physical_devices('GPU'))\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Camera sources\n",
    "CAMERA_SOURCES = {\n",
    "    \"camera1\": \"http://10.24.75.85:4747/video\",\n",
    "    \"camera2\": \"http://10.24.78.21:4747/video\",\n",
    "}\n",
    "frames = {name: Queue(maxsize=1) for name in CAMERA_SOURCES}\n",
    "FRAME_SKIP = 2  \n",
    "\n",
    "def detect_faces(frame):\n",
    "    \"\"\"Run RetinaFace on GPU and detect faces.\"\"\"\n",
    "    if frame is None or frame.size == 0:\n",
    "        return None\n",
    "\n",
    "    faces = RetinaFace.detect_faces(frame)  # RetinaFace uses MXNet by default\n",
    "\n",
    "    if isinstance(faces, dict) and faces:\n",
    "        for _, face in faces.items():\n",
    "            x1, y1, x2, y2 = face[\"facial_area\"]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def capture_and_process_camera(camera_name, url):\n",
    "    \"\"\"Capture video and run RetinaFace detection.\"\"\"\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] Unable to open {camera_name}. Check IP and connectivity.\")\n",
    "        return\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"[ERROR] Lost connection to {camera_name}\")\n",
    "            break\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % FRAME_SKIP == 0:\n",
    "            processed_frame = detect_faces(frame)\n",
    "            if processed_frame is not None:\n",
    "                try:\n",
    "                    frames[camera_name].put_nowait(processed_frame)  # Non-blocking\n",
    "                except:\n",
    "                    pass  \n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Start threads for each camera\n",
    "threads = []\n",
    "for name, url in CAMERA_SOURCES.items():\n",
    "    thread = threading.Thread(target=capture_and_process_camera, args=(name, url), daemon=True)\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Display video streams\n",
    "while True:\n",
    "    for name in CAMERA_SOURCES.keys():\n",
    "        try:\n",
    "            frame = frames[name].get_nowait()  # Non-blocking\n",
    "            cv2.imshow(f\"Live Stream - {name}\", frame)\n",
    "        except:\n",
    "            pass  # No frame available yet\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd35f3f-0a82-4d99-b0e9-6b07a04dbdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TensorFlow is using GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[http @ 0x7f8608014d80] Stream ends prematurely at 95921269, should be 18446744073709551615\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "from retinaface import RetinaFace\n",
    "\n",
    "# Enable GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"[INFO] TensorFlow is using GPU:\", tf.config.list_physical_devices('GPU'))\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Camera sources\n",
    "CAMERA_SOURCES = {\n",
    "    \"camera1\": \"http://10.24.75.85:4747/video\",\n",
    "    ##\"camera2\": \"http://10.24.78.21:4747/video\",\n",
    "}\n",
    "frames = {name: Queue(maxsize=1) for name in CAMERA_SOURCES}\n",
    "faces_queue = Queue(maxsize=10)  # Stores cropped face images\n",
    "\n",
    "def detect_faces(frame):\n",
    "    \"\"\"Run RetinaFace (TensorFlow) for face detection.\"\"\"\n",
    "    if frame is None or frame.size == 0:\n",
    "        return None\n",
    "\n",
    "    faces = RetinaFace.detect_faces(frame)  # RetinaFace internally uses TensorFlow\n",
    "\n",
    "    if isinstance(faces, dict) and faces:\n",
    "        for _, face in faces.items():\n",
    "            x1, y1, x2, y2 = face[\"facial_area\"]\n",
    "            cropped_face = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # Store cropped face for embedding extraction\n",
    "            if cropped_face.size > 0:\n",
    "                try:\n",
    "                    faces_queue.put_nowait(cropped_face)\n",
    "                except:\n",
    "                    pass  # Skip if queue is full\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def capture_and_process_camera(camera_name, url):\n",
    "    \"\"\"Capture video and process with RetinaFace.\"\"\"\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] Unable to open {camera_name}\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "        processed_frame = detect_faces(frame)\n",
    "\n",
    "        try:\n",
    "            frames[camera_name].put_nowait(processed_frame)\n",
    "        except:\n",
    "            pass  # Skip if queue is full\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Start camera threads\n",
    "for name, url in CAMERA_SOURCES.items():\n",
    "    thread = threading.Thread(target=capture_and_process_camera, args=(name, url), daemon=True)\n",
    "    thread.start()\n",
    "    time.sleep(1)\n",
    "\n",
    "# Display video\n",
    "while True:\n",
    "    for name in CAMERA_SOURCES.keys():\n",
    "        try:\n",
    "            frame = frames[name].get_nowait()\n",
    "            cv2.imshow(f\"Live Stream - {name}\", frame)\n",
    "        except:\n",
    "            pass  \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "444e4a20-35f1-4d82-8802-b1b66268e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/student/anaconda3/envs/tensorflow/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement mxnet-cu118 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for mxnet-cu118\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3741ab2-c6ed-4103-a121-f439767f032f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a482d-1b90-451a-9539-24a65d37b3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e460699-f9e6-4a34-a253-d1193592d01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
