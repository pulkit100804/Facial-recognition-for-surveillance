{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b06947",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from queue import Queue\n",
    "from pymongo import MongoClient\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from retinaface import RetinaFace\n",
    "from scipy.spatial.distance import cosine\n",
    "from flask import Flask, Response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18a572",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Configs\n",
    "# ---------------------------\n",
    "CAMERA_SOURCES = {\n",
    "    \"Camera 1\": \"http://10.24.82.153:4747/video\",\n",
    "    \"Camera 2\": \"http://10.24.82.100:4747/video\"  # Add more cameras as needed\n",
    "}\n",
    "MONGO_URI = \"mongodb+srv://pulkitshrivastavabtech2023:eNlJhr8xRuuQYJDX@facialrecognitiondatabs.l70mvub.mongodb.net/?retryWrites=true&w=majority&appName=FacialRecognitionDatabse\"\n",
    "\n",
    "frames = {name: Queue(maxsize=5) for name in CAMERA_SOURCES}\n",
    "processed_frames = {name: Queue(maxsize=5) for name in CAMERA_SOURCES}\n",
    "last_frame_cache = {}\n",
    "alerted_ids = set()\n",
    "\n",
    "# ---------------------------\n",
    "# Mongo Connection\n",
    "# ---------------------------\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[\"FaceRecognition\"]\n",
    "known_faces_collection = db[\"KnownFaces\"]\n",
    "\n",
    "# ---------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329f498",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load Model\n",
    "# ---------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "def match_faces(detected_embedding):\n",
    "    known_faces = list(known_faces_collection.find({}))\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    for known_face in known_faces:\n",
    "        for angle, known_embedding in known_face[\"embeddings\"].items():\n",
    "            score = cosine_similarity(np.array(detected_embedding), np.array(known_embedding))\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = {\n",
    "                    \"p_id\": known_face[\"p_id\"],\n",
    "                    \"angle\": angle,\n",
    "                    \"score\": best_score\n",
    "                }\n",
    "\n",
    "    return best_match if best_match and best_score > 0.6 else None\n",
    "\n",
    "def get_embedding(face_img, landmarks=None, partial=False):\n",
    "    try:\n",
    "        if face_img is None or face_img.size == 0:\n",
    "            return None\n",
    "\n",
    "        if partial and landmarks:\n",
    "            left_eye = landmarks[\"left_eye\"]\n",
    "            right_eye = landmarks[\"right_eye\"]\n",
    "            nose = landmarks[\"nose\"]\n",
    "\n",
    "            x_coords = [left_eye[0], right_eye[0], nose[0]]\n",
    "            y_coords = [left_eye[1], right_eye[1], nose[1]]\n",
    "            x1 = int(max(min(x_coords) - 20, 0))\n",
    "            y1 = int(max(min(y_coords) - 20, 0))\n",
    "            x2 = int(min(max(x_coords) + 20, face_img.shape[1]))\n",
    "            y2 = int(min(max(y_coords) + 20, face_img.shape[0]))\n",
    "\n",
    "            face_img = face_img[y1:y2, x1:x2]\n",
    "\n",
    "        face_img = cv2.resize(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB), (160, 160)).astype(np.float32) / 255.0\n",
    "        face_tensor = torch.from_numpy((face_img - 0.5) / 0.5).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = embedding_model(face_tensor)\n",
    "        return embedding.squeeze().cpu().numpy()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def detect_faces(camera_name):\n",
    "    while True:\n",
    "        if not frames[camera_name].empty():\n",
    "            frame = frames[camera_name].get()\n",
    "            height, width = frame.shape[:2]\n",
    "            faces = RetinaFace.detect_faces(frame)\n",
    "            results = []\n",
    "\n",
    "            if isinstance(faces, dict) and faces:\n",
    "                for _, face in faces.items():\n",
    "                    x1, y1, x2, y2 = face[\"facial_area\"]\n",
    "                    x1, y1 = max(0, x1), max(0, y1)\n",
    "                    x2, y2 = min(width - 1, x2), min(height - 1, y2)\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue\n",
    "\n",
    "                    cropped_face = frame[y1:y2, x1:x2]\n",
    "                    if cropped_face.size == 0:\n",
    "                        continue\n",
    "\n",
    "                    embedding = get_embedding(cropped_face)\n",
    "                    match = match_faces(embedding) if embedding is not None else None\n",
    "\n",
    "                    if not match or match[\"score\"] < 0.6:\n",
    "                        embedding_partial = get_embedding(cropped_face, face[\"landmarks\"], partial=True)\n",
    "                        if embedding_partial is not None:\n",
    "                            match_partial = match_faces(embedding_partial)\n",
    "                            if match_partial and match_partial[\"score\"] > (match[\"score\"] if match else 0):\n",
    "                                match = match_partial\n",
    "\n",
    "                    results.append((x1, y1, x2, y2, match))\n",
    "\n",
    "            for x1, y1, x2, y2, match in results:\n",
    "                label = match[\"p_id\"] if match else \"Unknown\"\n",
    "                color = (0, 255, 0) if match else (0, 0, 255)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, f\"{label}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            if processed_frames[camera_name].full():\n",
    "                processed_frames[camera_name].get()\n",
    "            processed_frames[camera_name].put(frame)\n",
    "            last_frame_cache[camera_name] = frame\n",
    "\n",
    "        time.sleep(0.03)\n",
    "\n",
    "def capture_frames(camera_name, url):\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] Cannot open {camera_name}\")\n",
    "        return\n",
    "\n",
    "    frame_counter = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        frame = cv2.resize(frame, (480, 360))\n",
    "        frame_counter += 1\n",
    "\n",
    "        if frame_counter % 5 == 0:\n",
    "            if frames[camera_name].full():\n",
    "                frames[camera_name].get()\n",
    "            frames[camera_name].put(frame.copy())\n",
    "\n",
    "        time.sleep(0.03)\n",
    "    cap.release()\n",
    "\n",
    "# ---------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b6f73",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Flask App\n",
    "# ---------------------------\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/video_feed/<camera_id>')\n",
    "def video_feed(camera_id):\n",
    "    def generate_stream(camera_id):\n",
    "        while True:\n",
    "            frame = last_frame_cache.get(camera_id, np.zeros((360, 480, 3), dtype=np.uint8))\n",
    "            ret, jpeg = cv2.imencode('.jpg', frame)\n",
    "            if not ret:\n",
    "                continue\n",
    "            yield (b'--frame\\r\\n'\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + jpeg.tobytes() + b'\\r\\n')\n",
    "            time.sleep(0.03)\n",
    "    return Response(generate_stream(camera_id), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "# ---------------------------\n",
    "# Start everything\n",
    "# ---------------------------\n",
    "if __name__ == '__main__':\n",
    "    for cam_name, cam_url in CAMERA_SOURCES.items():\n",
    "        threading.Thread(target=capture_frames, args=(cam_name, cam_url), daemon=True).start()\n",
    "        threading.Thread(target=detect_faces, args=(cam_name,), daemon=True).start()\n",
    "\n",
    "    app.run(host='0.0.0.0', port=5011, debug=False, use_reloader=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
