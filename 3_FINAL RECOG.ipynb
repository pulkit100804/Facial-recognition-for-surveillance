{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697b545f-d1d0-4f47-931e-18d17495f3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[http @ 0x7f0ff8001240] Stream ends prematurely at 41566616, should be 18446744073709551615\n",
      "Exception in thread Thread-9 (capture_frames):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/student/anaconda3/envs/tensorflow/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/student/anaconda3/envs/tensorflow/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_75/690512338.py\", line 151, in capture_frames\n",
      "  File \"/home/student/anaconda3/envs/tensorflow/lib/python3.10/tkinter/__init__.py\", line 1675, in configure\n",
      "    return self._configure('configure', cnf, kw)\n",
      "  File \"/home/student/anaconda3/envs/tensorflow/lib/python3.10/tkinter/__init__.py\", line 1665, in _configure\n",
      "    self.tk.call(_flatten((self._w, cmd)) + self._options(cnf))\n",
      "RuntimeError: main thread is not in main loop\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from queue import Queue\n",
    "from pymongo import MongoClient\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from retinaface import RetinaFace\n",
    "from scipy.spatial.distance import cosine\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# ---------------------------\n",
    "# Configs\n",
    "# ---------------------------\n",
    "CAMERA_SOURCES = {\n",
    "    \"Camera 1\": \"http://10.24.65.99:4747/video\"\n",
    "}\n",
    "MONGO_URI = \"mongodb+srv://pulkitshrivastavabtech2023:eNlJhr8xRuuQYJDX@facialrecognitiondatabs.l70mvub.mongodb.net/?retryWrites=true&w=majority&appName=FacialRecognitionDatabse\"\n",
    "frames = {name: Queue(maxsize=5) for name in CAMERA_SOURCES}\n",
    "processed_frames = {name: Queue(maxsize=5) for name in CAMERA_SOURCES}\n",
    "status_text = {}\n",
    "last_frame_cache = {}\n",
    "\n",
    "# ---------------------------\n",
    "# Mongo Connection\n",
    "# ---------------------------\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[\"FaceRecognition\"]\n",
    "known_faces_collection = db[\"KnownFaces\"]\n",
    "\n",
    "# ---------------------------\n",
    "# Load Model\n",
    "# ---------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "def match_faces(detected_embedding):\n",
    "    known_faces = list(known_faces_collection.find({}))\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    for known_face in known_faces:\n",
    "        for angle, known_embedding in known_face[\"embeddings\"].items():\n",
    "            score = cosine_similarity(np.array(detected_embedding), np.array(known_embedding))\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = {\n",
    "                    \"p_id\": known_face[\"p_id\"],\n",
    "                    \"angle\": angle,\n",
    "                    \"score\": best_score\n",
    "                }\n",
    "\n",
    "    return best_match if best_match and best_score > 0.6 else None\n",
    "\n",
    "def get_embedding(face_img, landmarks=None, partial=False):\n",
    "    try:\n",
    "        if face_img is None or face_img.size == 0:\n",
    "            return None\n",
    "\n",
    "        if partial and landmarks:\n",
    "            left_eye = landmarks[\"left_eye\"]\n",
    "            right_eye = landmarks[\"right_eye\"]\n",
    "            nose = landmarks[\"nose\"]\n",
    "\n",
    "            x_coords = [left_eye[0], right_eye[0], nose[0]]\n",
    "            y_coords = [left_eye[1], right_eye[1], nose[1]]\n",
    "            x1 = int(max(min(x_coords) - 20, 0))\n",
    "            y1 = int(max(min(y_coords) - 20, 0))\n",
    "            x2 = int(min(max(x_coords) + 20, face_img.shape[1]))\n",
    "            y2 = int(min(max(y_coords) + 20, face_img.shape[0]))\n",
    "\n",
    "            face_img = face_img[y1:y2, x1:x2]\n",
    "\n",
    "        if face_img is None or face_img.size == 0:\n",
    "            return None\n",
    "\n",
    "        face_img = cv2.resize(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB), (160, 160)).astype(np.float32) / 255.0\n",
    "        face_tensor = torch.from_numpy((face_img - 0.5) / 0.5).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = embedding_model(face_tensor)\n",
    "        return embedding.squeeze().cpu().numpy()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def detect_faces(camera_name):\n",
    "    while True:\n",
    "        if not frames[camera_name].empty():\n",
    "            frame = frames[camera_name].get()\n",
    "            height, width = frame.shape[:2]\n",
    "            faces = RetinaFace.detect_faces(frame)\n",
    "            results = []\n",
    "\n",
    "            if isinstance(faces, dict) and faces:\n",
    "                for _, face in faces.items():\n",
    "                    x1, y1, x2, y2 = face[\"facial_area\"]\n",
    "                    x1, y1 = max(0, x1), max(0, y1)\n",
    "                    x2, y2 = min(width - 1, x2), min(height - 1, y2)\n",
    "\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue\n",
    "\n",
    "                    cropped_face = frame[y1:y2, x1:x2]\n",
    "                    if cropped_face.size == 0:\n",
    "                        continue\n",
    "\n",
    "                    embedding = get_embedding(cropped_face)\n",
    "                    match = match_faces(embedding) if embedding is not None else None\n",
    "\n",
    "                    if not match or match[\"score\"] < 0.6:\n",
    "                        embedding_partial = get_embedding(cropped_face, face[\"landmarks\"], partial=True)\n",
    "                        if embedding_partial is not None:\n",
    "                            match_partial = match_faces(embedding_partial)\n",
    "                            if match_partial and match_partial[\"score\"] > (match[\"score\"] if match else 0):\n",
    "                                match = match_partial\n",
    "\n",
    "                    results.append((x1, y1, x2, y2, match))\n",
    "\n",
    "            for x1, y1, x2, y2, match in results:\n",
    "                label = match[\"p_id\"] if match else \"Unknown\"\n",
    "                color = (0, 255, 0) if match else (0, 0, 255)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, f\"{label}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "            if processed_frames[camera_name].full():\n",
    "                processed_frames[camera_name].get()\n",
    "            processed_frames[camera_name].put(frame)\n",
    "\n",
    "        time.sleep(0.03)\n",
    "\n",
    "def capture_frames(camera_name, url):\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] Cannot open {camera_name}\")\n",
    "        status_text[camera_name].config(text=\"Status: ‚ùå Unable to open feed\")\n",
    "        return\n",
    "\n",
    "    status_text[camera_name].config(text=\"Status: ‚úÖ Connected\")\n",
    "    frame_counter = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            status_text[camera_name].config(text=\"Status: ‚ö†Ô∏è Failed to read frame\")\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        frame = cv2.resize(frame, (480, 360))\n",
    "        frame_counter += 1\n",
    "\n",
    "        if frame_counter % 5 == 0:\n",
    "            if frames[camera_name].full():\n",
    "                frames[camera_name].get()\n",
    "            frames[camera_name].put(frame.copy())\n",
    "\n",
    "        if not processed_frames[camera_name].empty():\n",
    "            display_frame = processed_frames[camera_name].get()\n",
    "            last_frame_cache[camera_name] = display_frame\n",
    "        else:\n",
    "            display_frame = last_frame_cache.get(camera_name, frame)\n",
    "\n",
    "        time.sleep(0.03)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "def update_gui():\n",
    "    for cam_name in CAMERA_SOURCES:\n",
    "        if not processed_frames[cam_name].empty():\n",
    "            frame = processed_frames[cam_name].get()\n",
    "            last_frame_cache[cam_name] = frame\n",
    "        else:\n",
    "            frame = last_frame_cache.get(cam_name, np.zeros((360, 480, 3), dtype=np.uint8))\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(frame_rgb)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "        if cam_name in camera_labels:\n",
    "            camera_labels[cam_name].config(image=imgtk)\n",
    "            camera_labels[cam_name].imgtk = imgtk\n",
    "\n",
    "    root.after(30, update_gui)\n",
    "\n",
    "# ---------------------------\n",
    "# Tkinter GUI Setup\n",
    "# ---------------------------\n",
    "root = tk.Tk()\n",
    "root.title(\"üé• Real-Time Facial Recognition\")\n",
    "root.geometry(\"700x700\")\n",
    "root.configure(bg=\"#121212\")\n",
    "\n",
    "camera_labels = {}\n",
    "status_text = {}\n",
    "\n",
    "for cam_name, cam_url in CAMERA_SOURCES.items():\n",
    "    cam_label = tk.Label(root, text=cam_name, font=(\"Helvetica\", 16), fg=\"#00ff88\", bg=\"#121212\")\n",
    "    cam_label.pack(pady=(10, 2))\n",
    "\n",
    "    vid_label = tk.Label(root, bg=\"black\", width=480, height=360)\n",
    "    vid_label.pack()\n",
    "    camera_labels[cam_name] = vid_label\n",
    "\n",
    "    status = tk.Label(root, text=\"Status: Waiting...\", font=(\"Helvetica\", 12), fg=\"white\", bg=\"#121212\")\n",
    "    status.pack()\n",
    "    status_text[cam_name] = status\n",
    "\n",
    "    threading.Thread(target=capture_frames, args=(cam_name, cam_url), daemon=True).start()\n",
    "    threading.Thread(target=detect_faces, args=(cam_name,), daemon=True).start()\n",
    "\n",
    "update_gui()\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3897dfb-0fb7-4aac-88b4-61be6ab23d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
